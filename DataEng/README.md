
[The Future of the Data Engineer](https://towardsdatascience.com/the-future-of-the-data-engineer-4dcfa53800ab)  

Tag:`Maxime Beauchemin`,`2021`

**1, things move to cloud**  
This movement away from on-prem and open source solutions to the cloud and managed SaaS frees up data engineering resources to work on tasks unrelated to database management and reduced the running time.
With data engineers no longer responsible for managing compute and storage, their role is changing from infrastructure development to more performance-based elements of the data stack, or even specialized roles.

**2,It’s harder to gain consensus on governance — and that’s OK**  

**3,Change management is still a problem — but the right tools can help**    
When data would change, it would affect the whole company but no one would be notified. This data downtime (periods of time when data is missing, inaccurate, or otherwise erroneous) was costly, time-intensive, and painful to resolve. All too often, downtime would strike silently, and data teams would be left scratching their heads trying to figure out what went wrong, who was affected, and how they could fix it.

Data observability and lineage has certainly helped teams identify and fix problems, and even surface information about what broke and who was impacted.Still, change management is just as cultural as it is technical. If decentralized teams are not following processes and workflows that keep downstream consumers or even the central data platform team in the loop, then it’s challenging to handle change effectively.

Lineage and root cause analysis can get you half of the way there. For example, while Maxime was at Airbnb, Dataportal was built to democratize data access and empower all Airbnb employees to explore, understand, and trust data.

4,Data should be immutable — or else chaos will ensue  

5,The role of the data engineer is splintering   

The database engineer is becoming extinct, with data warehousing needs moving to the cloud, and data engineers are increasingly responsible for managing data performance and reliability.
The data engineer is the gatekeeper, responsible for educating data teams on best practices, most notably around efficiency (handling incremental loads), data modeling, and coding standards, and relying on data observability and DataOps to ensure that everyone is treating data with the same diligence.

The analytics engineer is a role that straddles data engineering and data analytics, and applies an analytical, business-oriented approach to working with data.The analytics engineer is like the data whisperer, responsible for ensuring that data doesn’t live in isolation from business intelligence and analysis.


6,Operational creep hasn’t gone away — it’s just been distributed  
Operational creep refers to the gradual increase of responsibilities over time, and unfortunately, it’s an all-too-common reality for data engineers. While modern tools can help make engineers more productive, they don’t always make their lives easier or less burdensome. In fact, they can often introduce more work or technical debt over time.

Still, even with the rise of more specialized roles and distributed data teams, the operational creep hasn’t gone away. Some of it has just been transferred over to other roles as technical savvy grows and more and more functions invest in data literacy.For instance, Maxime argues, what the analytics engineer prioritizes isn’t necessarily the same thing as a data engineer.

7,So, what’s next for the data engineer?    
While data team reporting structure and operational hierarchy is becoming more and more vertical, the scope of the data engineer is becoming increasingly horizontal and focused on performance and reliability — which is ultimately a good thing.

Focus breeds innovation and speed, which prevents data engineers from trying to boil the ocean, spin too many plates, or generally burn out. More roles on the data team mean traditional data engineering tasks (fielding ad-hoc queries, modeling, transformations, and even building pipelines) don’t need to fall solely on their shoulders. Instead, they can focus on what matters: ensuring that data is trustworthy, accessible, and secure at each point in its lifecycle.

The changing tooling landscape reflects this move towards a more focused and specialized role. DataOps makes it easy to schedule and run jobs; cloud data warehouses make it easy to store and process data in the cloud; data lakes allow for even more nuanced and complex processing use cases; and data observability, like application monitoring and observability before it, automates many of the rote and repetitive tasks related to data quality and reliability, providing a baseline level of health that allows the entire data organization to run smoothly.

With the rise of these new technologies and workflows, engineers also have a fantastic opportunity to own the movement towards treating data like a product. Building operational, scalable, observable, and resilient data systems is only possible if the data itself is treated with the diligence of an evolving, iterative product. Here’s where use case-specific metadata, ML-driven data discovery, and tools that can help us better understand what data actually matters and what can go the way of the dodos.

[The Downfall of the Data Engineer](https://maximebeauchemin.medium.com/the-downfall-of-the-data-engineer-5bfb701e5d6b) 

Tag:`Maxime Beauchemin`,`2017`

[The Rise of the Data Engineer](https://medium.com/free-code-camp/the-rise-of-the-data-engineer-91be18f1e603) 

Tag:`Maxime Beauchemin`,`2021`

[How Airbnb Achieved Metric Consistency at Scale](https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70)